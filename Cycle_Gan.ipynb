{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cycle Gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVwei4rsUtwPvVjb0bRIrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saulrega/pytorch/blob/main/Cycle_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0-WXdBzQyDi",
        "outputId": "d35e95d2-976c-483d-c951-ff4daeb5910d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch/'\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnilm5kqV0z4",
        "outputId": "1f5f52f5-8ffb-4035-8679-1f63c93c8f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch\n",
            "'Capas de red neuronal.ipynb'  'Documento sin título.gdoc'    Tensores.ipynb\n",
            "'Cycle Gan.ipynb'\t       'Primera red neuronal.ipynb'\n",
            " dl-pytorch\t\t       'Setup inicial.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aitorzip/PyTorch-CycleGAN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceGV28MGV02_",
        "outputId": "4884d1de-238e-4d6f-a82f-c86a508f8fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch-CycleGAN'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Total 60 (delta 0), reused 0 (delta 0), pack-reused 60\u001b[K\n",
            "Unpacking objects: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'PyTorch-CycleGAN'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyrX03RZV05_",
        "outputId": "8ddee44f-38a4-4e80-9f72-c7da465d1d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch/PyTorch-CycleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "sh ./download_dataset summer2winter_yosemite"
      ],
      "metadata": {
        "id": "CrnjbLnrV08w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv datasets/summer2winter_yosemite /content/drive/MyDrive/Colab\\ Notebooks/Deep\\ learning\\ pytorch/dl-pytorch/datasets/"
      ],
      "metadata": {
        "id": "hDTvaBDoV0_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch/dl-pytorch/datasets'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgCZoFQUV1Bv",
        "outputId": "d10e2637-733b-4d56-b432-ec6eb6464c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64x64_SIGNS\t cifar-10-batches-py\t summer2winter_yosemite\n",
            "64x64_SIGNS.zip  cifar-10-python.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    \n",
        "    conv_block = [ nn.ReflectionPad2d(1), #mejor padding\n",
        "                   nn.Conv2d(in_features, in_features, 3),\n",
        "                   nn.InstanceNorm2d(in_features), #BN para GANS\n",
        "                   nn.ReLU(True),\n",
        "                   nn.ReflectionPad2d(1), #mejor para conservar distribucion\n",
        "                   nn.Conv2d(in_features, in_features, 3),\n",
        "                   nn.InstanceNorm2d(in_features)\n",
        "                 ]\n",
        "    \n",
        "    self.conv_block = nn.Sequential(*conv_block)\n",
        "  def forward(self, x):\n",
        "    return self.conv_block(x) + x #una idea poderosa"
      ],
      "metadata": {
        "id": "OX_yldSMV1Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "    super(Generator,self).__init__()\n",
        "    \n",
        "    # Bloqueconvolucional\n",
        "    model = [ nn.ReflectionPad2d(3),\n",
        "              nn.Conv2d(input_nc, 64, 7), # I - 7 + 6 /1 +1 = I\n",
        "              nn.InstanceNorm2d(64),\n",
        "              nn.ReLU(True)\n",
        "            ]\n",
        "    \n",
        "    in_features = 64\n",
        "    out_features = in_features * 2\n",
        "    \n",
        "    #Encoding\n",
        "    for _ in range(2):\n",
        "      model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), #I/2\n",
        "                 nn.InstanceNorm2d(out_features),\n",
        "                 nn.ReLU(True)\n",
        "               ]\n",
        "      in_features = out_features\n",
        "      out_features = in_features*2\n",
        "\n",
        "    #transformaciones residuales\n",
        "    \n",
        "    for _ in range(n_residual_blocks):\n",
        "      model += [ResidualBlock(in_features)]\n",
        "    \n",
        "    #decoding\n",
        "    \n",
        "    out_features = in_features//2\n",
        "    for _ in range(2):\n",
        "      model += [ nn.ConvTransose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1), #2I\n",
        "                 nn.InstanceNorm2d(out_features),\n",
        "                 nn.ReLU(True)\n",
        "               ]\n",
        "      in_features = out_features\n",
        "      out_feature = in_features //2\n",
        "      \n",
        "    \n",
        "    #salida\n",
        "    model += [ nn.ReflectionPad2d(3),\n",
        "               nn.Conv2d(64, output_nc, 7), #I\n",
        "               nn.Tanh()\n",
        "            ]\n",
        "      \n",
        "    self.model = nn.Sequential(*model)\n",
        "      \n",
        "    def forward(self,x):\n",
        "      return self.model(x)"
      ],
      "metadata": {
        "id": "yqnIGRkfV1JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  \"PatchGAN: discrimina estilo o textura\"\n",
        "  def __init__(self, input_nc):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    model = [ nn.Conv2d(input_nc, 64, 4, stride=2, padding=1), #I/2\n",
        "              nn.LeakyReLU(0.2, in_place=True)\n",
        "            ]\n",
        "    \n",
        "    model += [ nn.Conv2d(64, 128, 4, stride=2, padding=1), #I/2\n",
        "               nn.InstanceNorm2d(128),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    \n",
        "    model += [ nn.Conv2d(128, 256, 4, stride=2, padding=1), #I/2\n",
        "               nn.InstanceNorm2d(256),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    \n",
        "    model += [ nn.Conv2d(256, 512, 4, padding=1), #I-1\n",
        "               nn.InstanceNorm2d(512),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    \n",
        "    # Flatten\n",
        "    model += [nn.Conv2d(512, 1, 4, padding=1)] #I-1\n",
        "    \n",
        "    self.model = nn.Sequential(*model)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ],
      "metadata": {
        "id": "7Zx7EofVV1MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch/dl-pytorch/')"
      ],
      "metadata": {
        "id": "gazN58bIV1O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/Deep\\ learning\\ pytorch/dl-pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATLxd_yV1R_",
        "outputId": "e4992831-931b-4b36-98b4-bd79c12d770d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets  optimizers_viz.py  plot_helpers.py  __pycache__  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "id": "hAEPsDxwV1VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visdom"
      ],
      "metadata": {
        "id": "_5XV3KIqg140"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob \n",
        "import random \n",
        "import os \n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from utils import ReplayBuffer, Logger\n",
        "\n",
        "from livelossplot import PlotLosses"
      ],
      "metadata": {
        "id": "oQZMDeMhV1YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, base_dir, transform=None, split='train'):\n",
        "    self.transform = transforms.Compose(transform)\n",
        "    self.files_A = sorted(glob.glob(os.path.join(base_dir, '{}/A/*.*'.format(split))))\n",
        "    self.files_B = sorted(glob.glob(os.path.join(base_dir, '{}/B/*.*'.format(split))))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return max(len(self.files_A), len(self.files_B))\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    image_A = self.transform(Image.open(self.files_A[idx]))\n",
        "    image_B = self.transform(Image.open(self.files_B[random.randint(0,len(self.files_B)-1)]))\n",
        "    return {'A': image_A, 'B': image_B}"
      ],
      "metadata": {
        "id": "hQAwLhrBV1av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=0\n",
        "n_epochs = 200\n",
        "batch_size = 2 #4\n",
        "lr = 0.0002\n",
        "size = 256\n",
        "input_nc = 3\n",
        "output_nc = 3\n",
        "decay_epoch= 100 #pending\n",
        "\n",
        "cuda = True\n",
        "n_cpu = 8\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/Deep learning pytorch/dl-pytorch/datasets/summer2winter_yosemite/'"
      ],
      "metadata": {
        "id": "lQyUwN7jb9w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "\n",
        "def weights_init_normal(m):\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "    torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
        "  elif isinstance(m, nn.BatchNorm2d):\n",
        "    torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "    torch.nn.init.constant(m.bias, 0.0)\n",
        "    \n",
        "netG_A2B = Generator(input_nc, output_nc)\n",
        "netG_B2A = Generator(input_nc, output_nc)\n",
        "netD_A = Discriminator(input_nc)\n",
        "netD_B = Discriminator(input_nc)\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "if cuda:\n",
        "  netG_A2B.to(device)\n",
        "  netG_B2A.to(device)\n",
        "  netD_A.to(device)\n",
        "  netD_B.to(device)\n",
        "  \n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()"
      ],
      "metadata": {
        "id": "tt7Qpxgab-Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciando optimizadores y schedulers"
      ],
      "metadata": {
        "id": "Aar_n_PgkQ2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                              lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "\n",
        "#schedulers (actualizar el learning rate de forma dinamica durante el entrenamiento)\n",
        "\n",
        "class LambdaLR():\n",
        "  def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "    assert ((n_epochs - decay_start_epoch) > 0)\n",
        "    self.n_epochs = n_epochs\n",
        "    self.offset = offset\n",
        "    self.decay_start_epoch = decay_start_epoch\n",
        "    \n",
        "  def step(self, epoch):\n",
        "    return 1 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, \n",
        "                                                   lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, \n",
        "                                                     lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, \n",
        "                                                     lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n"
      ],
      "metadata": {
        "id": "1bQxsMm2kS1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculando las perdidas"
      ],
      "metadata": {
        "id": "WrzjG5kokjjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs y targets\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "target_real = Tensor(batch_size).fill_(1.0)\n",
        "target_fake = Tensor(batch_size).fill_(0.0)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "#Dataloader\n",
        "\n",
        "transform = [ transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
        "              transforms.RandomCrop(size),\n",
        "              transforms.RandomHorizontalFlip(),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "            ]\n",
        "\n",
        "dataloader = DataLoader(ImageDataset(base_dir,transform=transform),\n",
        "                       batch_size=batch_size, shuffle=True, num_workers=n_cpu, drop_last=True)\n",
        "\n",
        "def Gen_GAN_loss(G, D, real, loss, target_real):\n",
        "  fake = G(real)\n",
        "  pred_fake = D(fake)\n",
        "  L = loss(pred_fake, target_real)\n",
        "  return L, fake\n",
        "\n",
        "def cycle_loss(G1, G2, real, loss):\n",
        "  recovered = G2(G1(real))\n",
        "  L = loss(recovered, real)\n",
        "  return L\n",
        "\n",
        "def identity_loss(G, real, loss):\n",
        "  same = G(real)\n",
        "  L = loss(same,real)\n",
        "  return L\n",
        "\n",
        "def Disc_GAN_loss(D2, fake2, real2, fake_2_buffer, loss, target_real, target_fake):\n",
        "  pred_real = D2(real2)\n",
        "  loss_D2_real = loss(pred_real, target_real)\n",
        "  \n",
        "  fake2 = fake_2_buffer.push_and_pop(fake2)\n",
        "  pred_fake = D2(fake2.detach())\n",
        "  loss_D2_fake = loss(pred_fake, target_fake)\n",
        "  loss_D2 = (loss_D2_real + loss_D2_fake) * 0.5\n",
        "  return loss_D2"
      ],
      "metadata": {
        "id": "-h5Zt491km6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento y visualización del entrenamiento"
      ],
      "metadata": {
        "id": "Xt298B6akrmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "id": "I_dz0eFHkxIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from livelossplot import PlotLosses\n",
        "from utils import Logger\n",
        "\n",
        "logger = Logger(n_epochs, len(dataloader), epoch=epoch)\n",
        "liveloss= PlotLosses()"
      ],
      "metadata": {
        "id": "PtJPvAuGk0cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch, n_epochs):\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    real_A = batch['A'].to(device)\n",
        "    real_B = batch['B'].to(device)\n",
        "    \n",
        "    # Generativas\n",
        "    optimizer_G.zero_grad()\n",
        "    \n",
        "    loss_GAN_A2B, fake_B = Gen_GAN_loss(netG_A2B, netD_B, real_A, criterion_GAN, target_real)\n",
        "    loss_GAN_B2A, fake_A = Gen_GAN_loss(netG_B2A, netD_A, real_B, criterion_GAN, target_real)\n",
        "    \n",
        "    loss_cycle_ABA = cycle_loss(netG_A2B, netG_B2A, real_A, criterion_cycle)\n",
        "    loss_cycle_BAB = cycle_loss(netG_B2A, netG_A2B, real_B, criterion_cycle)\n",
        "    \n",
        "    loss_identity_A = identity_loss(netG_B2A, real_A, criterion_identity)\n",
        "    loss_identity_B = identity_loss(netG_A2B, real_B, criterion_identity)\n",
        "    \n",
        "    loss_G = (loss_GAN_A2B + loss_GAN_B2A) + 10.0*(loss_cycle_ABA + loss_cycle_BAB) + 5.0 *(loss_identity_A + loss_identity_B)\n",
        "    loss_G.backward()\n",
        "    \n",
        "    optimizer_G.step()\n",
        "    \n",
        "    #Discriminativas\n",
        "    optimizer_D_A.zero_grad()\n",
        "    \n",
        "    loss_D_A = Disc_GAN_loss(netD_A, fake_A, real_A, fake_A_buffer, criterion_GAN, target_real, target_fake)\n",
        "    loss_D_A.backward()\n",
        "    optimizer_D_A.step()\n",
        "    \n",
        "    optimizer_D_B.zero_grad()\n",
        "    \n",
        "    loss_D_B = Disc_GAN_loss(netD_B, fake_B, real_B, fake_B_buffer, criterion_GAN, target_real, target_fake)\n",
        "    loss_D_B.backward()\n",
        "    optimizer_D_B.step()\n",
        "    \n",
        "    log_values = {'loss_G': loss_G,\n",
        "                  'loss_G_identity': (loss_identity_A + loss_identity_B),\n",
        "                  'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
        "                  'loss_G_cyle': loss_cycle_ABA + loss_cycle_BAB,\n",
        "                  'loss_D': loss_D_A + loss_D_B\n",
        "                 }\n",
        "    logger.log(log_values, images={'real_A': real_A,'real_B': real_B, 'fake_A': fake_A,'fake_B': fake_B  })\n",
        "  \n",
        "  liveloss.update(log_values)\n",
        "  liveloss.draw()\n",
        "    \n",
        "  lr_scheduler_G.step()\n",
        "  lr_scheduler_D_A.step()\n",
        "  lr_scheduler_D_B.step()\n",
        "  "
      ],
      "metadata": {
        "id": "0tFz8CKEk0gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vw5bIQ10k0jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4VEEpCHuk0mO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}